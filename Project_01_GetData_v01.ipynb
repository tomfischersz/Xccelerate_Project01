{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "    <h1>Course Project</h1>\n",
    "    <p>Scraping a local job site for data scientist jobs in HK</p>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_text(job_link):\n",
    "    _page = requests.get(job_link)\n",
    "    _soup = BeautifulSoup(_page.text, \"html.parser\")\n",
    "    #print(job_link)\n",
    "    x = _soup.find(name=\"div\", attrs={\"class\":\"jobsearch-JobComponent-description\"})\n",
    "    if x:\n",
    "        return x.text\n",
    "    else:\n",
    "        return \"Not Found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL = \"https://www.indeed.hk/viewjob?jk=2dfb473af85953b5\"\n",
    "#URL = \"https://www.indeed.hk/viewjob?jk=6567706422d33abe\"\n",
    "#get_job_text(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  79 jobs.\n",
      "start index for sites: 0 ending index: 70\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=0\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=10\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=20\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=30\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=40\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=50\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=60\n",
      "https://www.indeed.hk/jobs?q=%22data+scientist%22&start=70\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = 100\n",
    "\n",
    "columns = [\"job_title\", \"company_name\", \"details_link\", \"job_text\"]\n",
    "jobs_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "while True:\n",
    "    url = \"https://www.indeed.hk/jobs?q=%22data+scientist%22&start=\" + str(start)\n",
    "    time.sleep(1)  # ensuring at least 1 second between page grabs\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    # how many jobs there are?\n",
    "    if start == 0:\n",
    "        # a loop here is silly I know\n",
    "        for div in soup.find_all(name=\"meta\" , attrs={\"name\":\"description\"}):\n",
    "            matchObj = re.match( r\"^([0-9]+)\", div['content'])\n",
    "            num_jobs = matchObj.group()\n",
    "            end = math.floor((int(num_jobs)-1)/10) * 10\n",
    "            # data frame will contain more records, maybe because of duplicated sponsored jobs\n",
    "            # and also our last page contains more jobs than it should.\n",
    "            print(\"There are \", num_jobs, \"jobs.\")\n",
    "            print(\"start index for sites:\", start, \"ending index:\", end)\n",
    "            #end = 20\n",
    "\n",
    "    print(url)\n",
    "    start = start + 10\n",
    "    # somehow the main loop, for each single job per page (should be 16 jobs, but seems not always)\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        num = (len(jobs_df) + 1)\n",
    "        job_post = []\n",
    "        \n",
    "        # job title\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            job_post.append(a[\"title\"])\n",
    "        \n",
    "        # job company\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                job_post.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "                job_post.append(span.text.strip())\n",
    "\n",
    "        job_link = \"https://www.indeed.hk/viewjob?jk=\" + div[\"data-jk\"]\n",
    "        job_post.append(job_link)\n",
    "        job_text = get_job_text(job_link)\n",
    "        \n",
    "        #job_post.append(job_text[0:10])\n",
    "        job_post.append(job_text)\n",
    "        \n",
    "        #print(job_post)\n",
    "        jobs_df.loc[num] = job_post\n",
    "        \n",
    "    if start > end:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this now to a file. Further processing will be done in another script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv(\"ds_jobs_indeed_v01_20181101.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head()\n",
    "#print(jobs_df.iloc[0,3])\n",
    "# need to check for duplcates, there are a lot.\n",
    "sum(jobs_df.duplicated())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.shape #(128, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF SCRIPT\n",
    "\n",
    "The rest is templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL = \"https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "#URL = \"https://www.indeed.hk/jobs?q=%22data+scientist%22&l=\"\n",
    "URL = \"https://www.indeed.hk/jobs?q=%22data+scientist%22\"\n",
    "URL = \"https://www.indeed.hk/viewjob?jk=2dfb473af85953b5\"\n",
    "URL = \"https://www.indeed.hk/viewjob?jk=6567706422d33abe\"\n",
    "\n",
    "\n",
    "\n",
    "#    https://www.indeed.hk/jobs?q=%22data+scientist%22&l=\n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "#print(soup.prettify())\n",
    "\n",
    "#for x in soup.find_all(name=\"div\", attrs={\"class\":\"jobsearch-JobComponent-description\"}):\n",
    "#    print(x.text)\n",
    "#with open(\"indeed_html.txt\", \"w\") as text_file:\n",
    "#    text_file.write(soup.prettify())\n",
    "x = soup.find(name=\"div\", attrs={\"class\":\"jobsearch-JobComponent-description\"})\n",
    "#print(x.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0C1KiKFNLSTeoagfKR_iBMdGU9SgqzP7Goclj1knC2rZz8RByLEz8BsgzjaLoQa0qioYCsrfsEiWnLOOivI-1CXyZ5ODDVkudJreSEG7GCpk_65j_UwhX55pdMnIfYmIbURZ9FMTtCdSjmLBdfn_PR-hK3fgyoD5pGFlu32lqxNK08UTHGSVYzVzpRgic1AkwcxgBTVruRB8v17rhC1qiV40EcriOabpzQe5Ld8SpQKQyxGQyq6B1Q3hNUzTdIkniHL0Y5kaIj8npodWAf39v4UbB8S9hmhyDlOkfMPzR40HEI4AwNOWeOdhbleUheBuyqv4NEdjaSljhDZ62Ki1MRXUufTPXdByccVVlCQnyZJZ9O0s8eXTbuQIYWdImXCKMygLtp5pM96pdOPBwePE7pl2uSbK-Ky2A9MDm7d-ii0Uc1FbSjB9bpwnejreH5HQ5HKp9kt2RRjEVs6S7My_vwppyZTByqVIaqlPUrgmp04FBc3u2S_1fH2qf4amUfh-nPgQHHddjgDbhGCo5D4k9OTcUXqKwHUAoCQhdLpAIOGPbLHsaoctz2oLz7U9y64N-osxnmzlrA-Iwwn4NUwTNrhiBYEIknbXIII9y2cgHkkr7GiLOSs_yrvaJbm9JEGsqU6mTbU9VaNnvgXCbFBcMGivXgww_m1Z4Uiicp4S3dwc6kJvGmYX4DQ7wda_rJM5jA=&amp;vjs=3&amp;p=1&amp;sk=&amp;fvj=0\" id=\"sja1\" onclick=\"setRefineByCookie([]); sjoc('sja1',0); convCtr('SJ')\" onmousedown=\"sjomd('sja1'); clk('sja1');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0C1KiKFNLSTeoagfKR_iBMdGU9SgqzP7Goclj1knC2rZz8RByLEz8BsgzjaLoQa0qgaiv3bcZJOpbLSc2mJtxwWA9VNJhts16TnibGUfimIpiOLDmZnFgcm_L2c6IIBR7U5XxNy2x9KOmLtKObsD_JlDuuJM79gGxmR-X4g2MugbobOSaxv9df863wFiSKKNsbXTox3vjAV9wZU2eVeQTnbKgiHjkSSE0cY6iG-6YhUC9dMlu_UqdrNb9InW8nw05NRhsh8sKqtlzMeL4V-sqUcHKbx-CrnJz76fJUk1qY3PesBqeQIqLbMrA-twEk7OUCCzmV_ao1KO0T5uDJg4iytxM3jB75IZ1oHSPf5s92_NvSgpGKgTCMo33y2GcucPlUmYjlNJgiXMbqEF5ua1yj-Fma8B6vyDpT1sCQU08WPkWbqPA5KfwhaJNty7vTw2I0UWXFwLHEHgt_Rzc27LymcrarKRKLWLYo6EmCbRMLbwXPRFbI65f4mRG1pEIixzicqhnT3Y4tkloxu8DxhWkwQ5ojyRhE4ly2dQ7KiFgudNgzx4ArDHAS7Ul-dkWfVpwdtlgn0N2-Zxyer1sOCTKdCM89b6wt2WH5bn-gxA8vU_Xf8H1jxUSeLgXWpmBdFbV5I06lc68cjIwH9hOZqvkeUn6MH2uK9wMc8FW40kr0pd99fzlusG9iv&amp;vjs=3&amp;p=2&amp;sk=&amp;fvj=0\" id=\"sja2\" onclick=\"setRefineByCookie([]); sjoc('sja2',0); convCtr('SJ')\" onmousedown=\"sjomd('sja2'); clk('sja2');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0C1KiKFNLSTeoagfKR_iBMdGU9SgqzP7Goclj1knC2rZz8RByLEz8BsgzjaLoQa0qhxhTKY1Jp5Dg3tFhOkACFWrOGWboh-NMQADnzLrvIS6pkKXPgn3ze4Jm1jt-5pf2qeJ_S580DymC5AsQO_ooWN1OM0elqdAeSCVknW3wJyz0J1-6mhabbcL22zEm33HhQ22wAA5IzC6DwHqe0FH8s9HPbFG6jf_SrpF3uM25zroyu4_LY_FtU4An38KZKIv47hsWoFfSh6oHOwmNZE046vu0idCBIUdtg9N65-qPttJjC9AIhq8_G5leDn5SFecBwHQiARmNbLK5-wTZf17VpTD3235O6hH_pXAw3cD2daDhGGyyLQXMqkyNoCHnWBwu3dMvRJRb5DiMAOrnS6r1o_wqF8QDOFUt1fJcyFZzw3YfN5DJL0zFDycoNVP4F3qc3_SQbGpkDrQ_1OoMxsG8jcqaJXZjeXNJtIe-LtDPFiBJGndnOUFI3vl60rIvzzFhaxR_X0gV9z3Usn29EuoTo81T_ko6EA1BieEyNR2jCfkH_6Dr0xnMz8C7hS832bsNSwiU5VGb2Pgp__3vLIBjqGh4S8dfbkz32_c0q3pcAuKZpzsISueFQNmhNpyGqCfvSEYc99LEDyTEAgsr94M-rdOxjhjY7ZGm9twozOziYKkKXd4XUY7Ate&amp;vjs=3&amp;p=3&amp;sk=&amp;fvj=0\" id=\"sja3\" onclick=\"setRefineByCookie([]); sjoc('sja3',0); convCtr('SJ')\" onmousedown=\"sjomd('sja3'); clk('sja3');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=23768ba7988bcd78&amp;fccid=683f1fb26dcffb4c&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[0],true,0);\" onmousedown=\"return rclk(this,jobmap[0],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Supply Chain Data Scientist\">Supply Chain <b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=c1c83d3135356139&amp;fccid=55c55b2c488e1a45&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[1],true,0);\" onmousedown=\"return rclk(this,jobmap[1],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=2011973ef100418c&amp;fccid=38c0d5e4f2a99768&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[2],true,0);\" onmousedown=\"return rclk(this,jobmap[2],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=d1e710d3d5a4d45b&amp;fccid=7205cf60d362cea1&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[3],true,0);\" onmousedown=\"return rclk(this,jobmap[3],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=25caad1ec1d1ff7a&amp;fccid=5d898ab80c3f3e38&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[4],true,0);\" onmousedown=\"return rclk(this,jobmap[4],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist / Quantitative Analyst\"><b>Data</b> <b>Scientist</b> / Quantitative Analyst</a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=5fb4aa72442e34e1&amp;fccid=55bf6ffe5c42e816&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[5],true,0);\" onmousedown=\"return rclk(this,jobmap[5],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist - Hong Kong\"><b>Data</b> <b>Scientist</b> - Hong Kong</a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=7c4e3ed4b7d830af&amp;fccid=f1943ec5b4031bab&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[6],true,0);\" onmousedown=\"return rclk(this,jobmap[6],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist / Computational Scientist\"><b>Data</b> <b>Scientist</b> / Computational <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=af25aa05f0edbc76&amp;fccid=afefea0edad5ffb5&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[7],true,0);\" onmousedown=\"return rclk(this,jobmap[7],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Research Data Scientist /Big Data Engineer,AI Dept\">Research <b>Data</b> <b>Scientist</b> /Big <b>Data</b> Engineer,AI Dept</a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=68468f841bbf0da8&amp;fccid=c604b374adac7e5f&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[8],true,0);\" onmousedown=\"return rclk(this,jobmap[8],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Junior Data Scientist\">Junior <b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=319296b51921a080&amp;fccid=7e57982cb894da40&amp;vjs=3\" onclick=\"setRefineByCookie([]); return rclk(this,jobmap[9],true,0);\" onmousedown=\"return rclk(this,jobmap[9],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0C1KiKFNLSTeoagfKR_iBMdGU9SgqzP7Goclj1knC2rZz8RByLEz8BsgzjaLoQa0qgaiv3bcZJOpWLZzi_7GLThs8_li16jTdY42fd-EdvHSkBysUNKiZtHKqwO0pNTePpN0MpIrqT3K8oMcq6V3WRv1pL8chaBomHJL3lbSS4d5RTlVtbSmQ49Mt_jfGuAY4BtPULgQ5Jddyd-EWEXsZSZB1EuNsTSSCjpt1xT5sd4aZpr7S8k7HpgNk3IEy4Im--MKp9xAjH2qGiWFK5dY9tDIbAzetVqdtfRgIMSWmrR-izztU6oYqZD_s2q3fu2Py2ma2bt4OtWp4EmMez2JBEynrMrVBDgBjfFL9i2g8pMqzVxyTm23yCB8bE8FhO6Var11mH5npDCc6r28Lpii8dfuLHGAjk1HyFiXKZpL8L_B8p5HISau3NguVFYLugmfXbX3vLZ81m8RRCACO7mjbbvVsls1b45qguUKH4kFgch5LUhgLIesCju7cBvz6BXRnnMp49rQspZFEDXdAToAIuXgAXdo5Rma44YAN1w-imhM9wTWqamYBNyDjKXWNxzdnigDv3ShI_kqh7a2lyzdhst57ywQ3rHKkk3FFC4M1O1Gy3PnGwjS9pcHJERZYEgg_mKTjAD-K__6zIxXq8r00qYqRAal8EUP7hcWEDlKgUb8qw_MdBdwIdilTXuttPZ7i0=&amp;vjs=3&amp;p=4&amp;sk=&amp;fvj=0\" id=\"sja4\" onclick=\"setRefineByCookie([]); sjoc('sja4',0); convCtr('SJ')\" onmousedown=\"sjomd('sja4'); clk('sja4');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist - Media\"><b>Data</b> <b>Scientist</b> - Media</a>\n",
      "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0C1KiKFNLSTeoagfKR_iBMdGU9SgqzP7Goclj1knC2rZz8RByLEz8BsgzjaLoQa0qgaiv3bcZJOpWLCWMydEfk0DPwEc0D6uO2G2AihscvH80KGXR7lgXGsimXU_uUYQJqHDrwEJc7ZgByyqIJmyqBLFvzDF0NgeOHDrZCU9nF6sOEeJWdKQ-aLsQPMh0tvNT_1pgudk9t4Z0WdCCxfD5NbF10Ym6KGhtPFD90vUcWJvzkUmUMKdY4V7HHU2UhfPoM8rIQwQcLfN4ZHR739rwyb3wL_lkzzEy6Ts-V9_bw2KcsSMIdTHzlOShqEfA6Z7TNkw1uLtqlfntUJq10mKMtSWP3oL61AwGMdahVIQ8Hec74-e9bDoGdyqgygV6HU0NqWaEy3_uvdzbGwlhvYyiu5w8fpvTZekpKuJhndgFfs9pI03xl6geIDmtyiw4HTkqhKhmvrX_Pp2ku9qPkCtQlnh_j3Y5lazVSxWIhqAlxY3tQNPiD44uODPMdpolWwDhm9bpqH9kHk7U8Y93FM7liOLvc7a9PxpXpj9dx2vRoJiAQRGO2fXO79VUwnq_hD3wLzBTqUKIbYpWcYBnv1sSDOA7w9-YuZjvaARwEWuUPFPxksOE8anKZAAYhu9_7I2agMtNzZl43Bc3P3Hee2fx0QtCjMlVoEM4xPnQS_6Uoy4MFGr0Xejdcp&amp;vjs=3&amp;p=5&amp;sk=&amp;fvj=0\" id=\"sja5\" onclick=\"setRefineByCookie([]); sjoc('sja5',0); convCtr('SJ')\" onmousedown=\"sjomd('sja5'); clk('sja5');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist\"><b>Data</b> <b>Scientist</b></a>\n",
      "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0C1KiKFNLSTeoagfKR_iBMdGU9SgqzP7Goclj1knC2rZz8RByLEz8BsgzjaLoQa0qi9JupGlNRPmbPm9VeqpzicW8ttJ3z5oSE-gBhHM2fUEpCIZhfMEIx0f1OaICFLPM79LOw0g79HD80xXZIJwlvaGhROu4-COsfo-QoFTy0JeV3vqSiswb9oEDLESn7KYAfXojosmzNHmj6lmcBezkoINprPswqO0Lp4M8P4DxGU0XDmwVWSpRWexPf04X3cQl74Wb-IN8y6UVUmhpWsTv54B27t8htLv8cyrhiyWLJ1h0HceL6m8Y3hdHA-oNux1IuTYYmsjvH2JM_7Mtu3u4VpUwvBynPDqO1HRfFGbIpfKixPx5ucOnroic9bTNO_vymHiylD9KhlffYwY7Qv7YxqhiTAChHUnWYV0YOu0cLQHfEaA5z3OIqofXVSP6IV_jiXVRhAAKHYvkpo1XfJsJinD51OS_GxgMCKlTjgCUAN-bTigsk6bd7H_Ue4rXYDUIn18kRmagHuj-GgP8sBEiGXYRFBBb0-3_3WCSRCcxRjivY_t4q3ehHW90hj6qDGXaCWVMad0T_Ck9dFUREV1UDVn23AYRSh-TFd8tQgj_awWOFjzgoF9iTMwPd18uFrOCf8tIf1Ylx9qZ5xkERdvWnLoeOXiV0P_a0uVhWs3_YQXi0o2e-dkQ_W2LN9YuRylRDI0AdmKex1J0eJ4Jot8miO8_Ibikuz4o8=&amp;vjs=3&amp;p=6&amp;sk=&amp;fvj=0\" id=\"sja6\" onclick=\"setRefineByCookie([]); sjoc('sja6',0); convCtr('SJ')\" onmousedown=\"sjomd('sja6'); clk('sja6');\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist / Computational Scientist\"><b>Data</b> <b>Scientist</b> / Computational <b>Scientist</b></a>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Supply Chain Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Quantitative Analyst',\n",
       " 'Data Scientist - Hong Kong',\n",
       " 'Data Scientist / Computational Scientist',\n",
       " 'Research Data Scientist /Big Data Engineer,AI Dept',\n",
       " 'Junior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Media',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / Computational Scientist']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        #print(div)\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            print(a)\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.indeed.hk/viewjob?jk=8fac5bf3bd04d950',\n",
       " 'https://www.indeed.hk/viewjob?jk=1ab9ad946450576f',\n",
       " 'https://www.indeed.hk/viewjob?jk=f1621540076157c1',\n",
       " 'https://www.indeed.hk/viewjob?jk=6567706422d33abe',\n",
       " 'https://www.indeed.hk/viewjob?jk=d92b5c3ca5f3d1f7',\n",
       " 'https://www.indeed.hk/viewjob?jk=2dfb473af85953b5',\n",
       " 'https://www.indeed.hk/viewjob?jk=b3b7b9e98a61c1fa',\n",
       " 'https://www.indeed.hk/viewjob?jk=8065aee734f99b7c',\n",
       " 'https://www.indeed.hk/viewjob?jk=dec891350591d503',\n",
       " 'https://www.indeed.hk/viewjob?jk=b4ecafcc9ba3d85b',\n",
       " 'https://www.indeed.hk/viewjob?jk=608c233395777324',\n",
       " 'https://www.indeed.hk/viewjob?jk=a08880d50ab5b9b2',\n",
       " 'https://www.indeed.hk/viewjob?jk=65b3be9b13fea89b',\n",
       " 'https://www.indeed.hk/viewjob?jk=c1c83d3135356139',\n",
       " 'https://www.indeed.hk/viewjob?jk=a59b9777a43f6a69',\n",
       " 'https://www.indeed.hk/viewjob?jk=3d6b604aed24017e']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.indeed.hk/viewjob?jk=7400947080a2c1ef\n",
    "\n",
    "def extract_link_for_details(soup):\n",
    "    link_details = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "#        print(div[\"data-jk\"])\n",
    "        link_details.append(\"https://www.indeed.hk/viewjob?jk=\" + div[\"data-jk\"])\n",
    "    return(link_details)\n",
    "\n",
    "extract_link_for_details(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the details page\n",
    "\n",
    "URL = \"https://www.indeed.hk/viewjob?jk=8fac5bf3bd04d950\"\n",
    "page_details = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup_details = BeautifulSoup(page_details.text, \"html.parser\")\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "#print(soup_details.prettify())\n",
    "\n",
    "with open(\"indeed_details_html.txt\", \"w\") as text_file:\n",
    "    text_file.write(soup_details.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Terminal 1',\n",
       " 'Cogs Agency HK',\n",
       " 'RADICA SYSTEMS LIMITED',\n",
       " 'BAH Partners',\n",
       " 'Lab Viso Limited',\n",
       " 'Cathay Pacific',\n",
       " 'AXA',\n",
       " 'Neo Derm Ltd.',\n",
       " 'IBM',\n",
       " 'Thinkcol.AI',\n",
       " 'AUREXIA Consulting',\n",
       " 'Libbler',\n",
       " 'Credit Suisse',\n",
       " 'SOUTH CHINA MORNING POST PUBLISHERS LTD',\n",
       " 'Hotmob Limited',\n",
       " 'ELEVATE HONG KONG HOLDINGS LIMITED']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup):\n",
    "    companies = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)\n",
    " \n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Visualization skills. Design data collection, integration and retention requirements. Conduct data analysis and create algorithms to predict probabilities....',\n",
       " 'They are looking to hire a Data Scientist, Director, to help enhancing such capabilities. Solid experience in data science, machine learning, Natural Language...',\n",
       " 'Implement data science and data analytic models in common languages. Devise technical data analytic or data science solutions to open business problem....',\n",
       " 'Experience with Big Data. 2-8 years years of experience working as a quantitative analyst or data scientist in any area....',\n",
       " 'We are looking for a talented Data Scientist to join our team. Analyse unstructured data (e.g. (i) extract entity from the unstructured data;...',\n",
       " 'Essential to have strong understanding in database concepts & data modelling, business intelligence disciplines & data management tools....',\n",
       " 'Data Scientist (180003VK). Big data/ Data Modelling. 3+ years of relevant working experience in data analytics field as statistician / analyst / data scientist....',\n",
       " 'Undertake processing of structure and unstructured data. Get involves in preparation of data visualization reports and analytical dashboards....',\n",
       " 'Job Description Do you want to be a consultant? Here at IBM Global Business Services (GBS) we live and breathe a client-first mindset in everything we do. We...',\n",
       " 'Knowledge in building data solution for questioning answering/dialog system is a plus. Providing assistance with model implementation and integration at all...',\n",
       " 'What you will be doing as a Data Scientist :. Passionate about data, models and visualizations. Degree in Statistics, Mathematics, Data Science, Engineering,...',\n",
       " '5+ years of experience as data scientist. Well established hedge fund is seeking an experienced data scientist to join their team in Hong Kong....',\n",
       " 'Data Scientist #114944. You have experience in the areas of data analytics, data mining and machine learning. You are passionate about software and data....',\n",
       " 'Create data tools to help streamline and automate workflows for Data Analytics & Insights team. Enhance data collection processes to include data from 1st and...',\n",
       " 'Architect, implement and deploy new data models and data processes in production. Enhance data collection processes to include data from 1st and 3rd party...',\n",
       " 'We are seeking an ambitious Data Scientist to play a leading role on our Data & Analytics team to use data to accelerate business-driven sustainability....']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup):\n",
    "    summaries = []\n",
    "    spans = soup.findAll('span', attrs={'class': 'summary'})\n",
    "    for span in spans:\n",
    "        summaries.append(span.text.strip())\n",
    "    return(summaries)\n",
    "\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Terminal 1',\n",
       " 'Cogs Agency HK',\n",
       " 'RADICA SYSTEMS LIMITED',\n",
       " 'BAH Partners',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Nothing_found',\n",
       " 'Hotmob Limited',\n",
       " 'ELEVATE HONG KONG HOLDINGS LIMITED']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup):\n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            salaries.append(div.find('nobr').text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"sjcl\"})\n",
    "                div_three = div_two.find(\"div\")\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append(\"Nothing_found\")\n",
    "    return(salaries)\n",
    "extract_salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
